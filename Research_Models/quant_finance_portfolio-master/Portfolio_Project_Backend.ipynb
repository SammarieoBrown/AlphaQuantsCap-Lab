{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9DJfeE9vCxIu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Portfolio Backend\n",
    "\n",
    "This notebook intends to build a python framework to manage your investment portfolio. \n",
    "\n",
    "We assume stocks are sold on a FIFO basis, although the functions defined in this notebook will be able to deal with other selling orders. We also assume that the price of a stock bought/sold is the closing market price of said stock on a given day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdAJgJ57Etpr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as wb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, gmean, cauchy\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ek6fnQz-CfwU",
    "outputId": "6578d1b6-d5c1-421e-b639-2ab35b1ae62d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_10312/1416426469.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mtransactions_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"https://s3.amazonaws.com/www.yourdatasurfer.com/test_stock_transactions.csv\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0minvestment_transactions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtransactions_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0minvestment_transactions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Open date'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_datetime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minvestment_transactions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Open date'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0minvestment_transactions\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    480\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    481\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 482\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    483\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    484\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 811\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    812\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    813\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1038\u001B[0m             )\n\u001B[0;32m   1039\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \"\"\"\n\u001B[1;32m--> 222\u001B[1;33m         self.handles = get_handle(\n\u001B[0m\u001B[0;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m             \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    607\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    608\u001B[0m     \u001B[1;31m# open URLs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 609\u001B[1;33m     ioargs = _get_filepath_or_buffer(\n\u001B[0m\u001B[0;32m    610\u001B[0m         \u001B[0mpath_or_buf\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    611\u001B[0m         \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36m_get_filepath_or_buffer\u001B[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001B[0m\n\u001B[0;32m    310\u001B[0m         \u001B[1;31m# assuming storage_options is to be interpreted as headers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    311\u001B[0m         \u001B[0mreq_info\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0murllib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mRequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 312\u001B[1;33m         \u001B[1;32mwith\u001B[0m \u001B[0murlopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreq_info\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mreq\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    313\u001B[0m             \u001B[0mcontent_encoding\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreq\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mheaders\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Content-Encoding\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mcontent_encoding\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"gzip\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36murlopen\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    210\u001B[0m     \u001B[1;32mimport\u001B[0m \u001B[0murllib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 212\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0murllib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0murlopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    213\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001B[0m in \u001B[0;36murlopen\u001B[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[0;32m    212\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    213\u001B[0m         \u001B[0mopener\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_opener\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 214\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mopener\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    215\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0minstall_opener\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopener\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001B[0m in \u001B[0;36mopen\u001B[1;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[0;32m    521\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mprocessor\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_response\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    522\u001B[0m             \u001B[0mmeth\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocessor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmeth_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 523\u001B[1;33m             \u001B[0mresponse\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmeth\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreq\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    524\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    525\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresponse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001B[0m in \u001B[0;36mhttp_response\u001B[1;34m(self, request, response)\u001B[0m\n\u001B[0;32m    630\u001B[0m         \u001B[1;31m# request was successfully received, understood, and accepted.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    631\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m200\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[0mcode\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m300\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 632\u001B[1;33m             response = self.parent.error(\n\u001B[0m\u001B[0;32m    633\u001B[0m                 'http', request, response, code, msg, hdrs)\n\u001B[0;32m    634\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001B[0m in \u001B[0;36merror\u001B[1;34m(self, proto, *args)\u001B[0m\n\u001B[0;32m    559\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mhttp_err\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    560\u001B[0m             \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'default'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'http_error_default'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0morig_args\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 561\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_chain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    562\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    563\u001B[0m \u001B[1;31m# XXX probably also want an abstract factory that knows when it makes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001B[0m in \u001B[0;36m_call_chain\u001B[1;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[0;32m    492\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mhandler\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mhandlers\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    493\u001B[0m             \u001B[0mfunc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhandler\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmeth_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 494\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    495\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mresult\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    496\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001B[0m in \u001B[0;36mhttp_error_default\u001B[1;34m(self, req, fp, code, msg, hdrs)\u001B[0m\n\u001B[0;32m    639\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mHTTPDefaultErrorHandler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseHandler\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    640\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mhttp_error_default\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmsg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhdrs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 641\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mHTTPError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreq\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfull_url\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmsg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhdrs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    642\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    643\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mHTTPRedirectHandler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseHandler\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mHTTPError\u001B[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "transactions_path = \"https://s3.amazonaws.com/www.yourdatasurfer.com/test_stock_transactions.csv\"\n",
    "investment_transactions = pd.read_csv(transactions_path)\n",
    "investment_transactions['Open date'] = pd.to_datetime(investment_transactions['Open date'])\n",
    "investment_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYRdnqmNE9Nm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next code block defines a series of functions that will be used throughout the notebook, especially for the objects Stock and Position. More functions will be added for building the portfolio and within the classes (objects) themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NgjljlQEsfD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def import_stock_data(tickers, start_date = '2010-1-1', end_date = datetime.today().strftime('%Y-%m-%d')):\n",
    "    data = pd.DataFrame()\n",
    "    if len([tickers]) ==1:\n",
    "        data[tickers] = wb.DataReader(tickers, data_source='yahoo', start = start_date, end = end_date)['Adj Close']\n",
    "        data = pd.DataFrame(data)\n",
    "    else:\n",
    "        for t in tickers:\n",
    "            data[t] = wb.DataReader(t, data_source='yahoo', start = start_date, end = end_date)['Adj Close']\n",
    "    return data\n",
    "\n",
    "def import_stock_dividends(tickers):\n",
    "    \"\"\"\n",
    "    Fetches and returns the dividends of a given stock.\n",
    "    Due to practical matters, this function will return all dividend history of a stock up until today.\n",
    "    It cannot be subseted when imported.\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    if len([tickers]) ==1:\n",
    "        data[tickers] = wb.DataReader(tickers, data_source='yahoo-dividends')['value']\n",
    "        data = pd.DataFrame(data)\n",
    "    else:\n",
    "        for t in tickers:\n",
    "            data[t] = wb.DataReader(t, data_source='yahoo-dividends')['value']\n",
    "    return data\n",
    "\n",
    "def subset_by_dateindex(data, start_date=None, end_date=None, date_position=\"index\"):\n",
    "    \"\"\"\n",
    "    Subsets dataframe by dates (index)\n",
    "    Inputs:\n",
    "    start_date: (str) date FROM which to subset\n",
    "    end_date: (str) date TO which to subset\n",
    "    date_position: (str) index or name of column in which dates are \n",
    "    \"\"\"\n",
    "    if date_position != \"index\":\n",
    "        data = data.set_index('Date')\n",
    "        \n",
    "    if (start_date == None) & (end_date == None):\n",
    "        return data\n",
    "    elif (start_date == None) & (end_date != None):\n",
    "        return data[data.index <= end_date]\n",
    "    elif (start_date != None) & (end_date == None):\n",
    "        return data[data.index >= start_date]\n",
    "    elif (start_date != None) & (end_date != None):\n",
    "        return data[(data.index >= start_date) & (data.index <= end_date)]\n",
    "    else:\n",
    "        print(\"Wrong input\")\n",
    "        \n",
    "def sell_order(purchase_history, sell_date, sell_quantity, order = \"FIFO\"):\n",
    "    \"\"\"\n",
    "    Determines which stocks we are going to sell. \n",
    "    First in First Out? (FIFO)\n",
    "    Last in First Out? (LIFO)\n",
    "    Cheapest to Most Expensive? Low to High? (L2H)\n",
    "    Most Expensive to Cheapest? High to Low? (H2L)\n",
    "    \"\"\"\n",
    "    def purchase_history_edit(purchase_history, sell_date, sell_quantity):\n",
    "        row_num = 0\n",
    "        while sell_quantity != 0:\n",
    "            ith_row = purchase_history.iloc[row_num]\n",
    "            ith_quantity = ith_row.Shares\n",
    "            if sell_quantity == ith_quantity:\n",
    "                purchase_history.iloc[row_num, 1] = 0\n",
    "                sell_quantity = 0\n",
    "            elif (sell_quantity - ith_quantity) < 0:\n",
    "                ith_quantity_left = abs(sell_quantity - ith_quantity)\n",
    "                purchase_history.iloc[row_num, 1] = ith_quantity_left\n",
    "                sell_quantity = 0\n",
    "                row_num += 1\n",
    "            elif (sell_quantity - ith_quantity) > 0:\n",
    "                sell_quantity = sell_quantity - ith_quantity\n",
    "                purchase_history.iloc[row_num, 1] = 0\n",
    "                row_num += 1\n",
    "        return purchase_history\n",
    "    \n",
    "    if order == \"FIFO\":\n",
    "        purchase_history.sort_values(by='Date', ascending = True, inplace=True)\n",
    "        return purchase_history_edit(purchase_history, sell_date, sell_quantity)\n",
    "    \n",
    "    elif order == \"L2H\":\n",
    "        purchase_history.sort_values(by='Price', ascending = True, inplace=True)\n",
    "        return purchase_history_edit(purchase_history, sell_date, sell_quantity)\n",
    "    \n",
    "    elif order == \"LIFO\":\n",
    "        purchase_history.sort_values(by='Date', ascending = False, inplace=True)\n",
    "        return purchase_history_edit(purchase_history, sell_date, sell_quantity)\n",
    "    \n",
    "    elif order == \"L2H\":\n",
    "        purchase_history.sort_values(by='Price', ascending = False, inplace=True)\n",
    "        return purchase_history_edit(purchase_history, sell_date, sell_quantity)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9m6DDZxOFhUL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Great! Now that we have defined functions to (1) import historical data for any stock, (2) import historical dividends of stock, (3) subset any dataframe by date (at index position), and (4) define the order in which stocks will be sold (default FIFO), let's make our first class: **Stock**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNOx3KBzFc_W",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Stock:\n",
    "    # This class will define the information of a stock\n",
    "    def __init__(self, ticker):\n",
    "        self.ticker = ticker\n",
    "        self.historical_data = import_stock_data(self.ticker, start_date=\"1970-1-1\")\n",
    "        self.historical_daily_returns = ((self.historical_data/self.historical_data.shift(1))-1)\n",
    "        try:\n",
    "            self.dividends = import_stock_dividends(self.ticker)\n",
    "        except:\n",
    "            self.dividends = pd.DataFrame({\"value\":0}, index=['1970-1-1'])\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.ticker\n",
    "        \n",
    "    def plot_stock(self, start_date=None, end_date=None):\n",
    "        return subset_by_dateindex(self.historical_data, start_date=start_date, end_date=end_date).plot(figsize=(15,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_Xl3n0YF8cV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's see how it works.\n",
    "\n",
    "We simply define the ticker of the stock and the class will load the data from the earliest date, until today. We can also use the plot_stock method to plot the prices of the given stock between two specified dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "colab_type": "code",
    "id": "1Dx8wAV1F58k",
    "outputId": "365fde30-57b3-4387-f963-9ee2d2067fa4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aapl = Stock('AAPL')\n",
    "aapl.historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "DiqYGHxxFhLM",
    "outputId": "1df94cb1-8ea5-4925-d269-b1bc0c3c742a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aapl.plot_stock(start_date=\"2015-1-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-OnviiWGuft",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we would like to know what our position of a given stock is. Let's define said class as **Position**.\n",
    "\n",
    "This class is quite important, since it must contain methods to update the values (ex - equity) of a position on any given day, and update the data regarding your position if you buy or sell a number of stocks on a given day.\n",
    "\n",
    "Hence, this class contain three methods that are of paramount importance:\n",
    "* .buy(),\n",
    "* .sell(),\n",
    "* .update()\n",
    "\n",
    "The only things needed to use these methods are the quantity of stocks bought/sold and the date (date when the market IS open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WIP4Ob6GV5W",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Position:\n",
    "    def __init__(self, Stock):\n",
    "        self.stock = Stock\n",
    "        self.shares = 0\n",
    "        self.equity = 0\n",
    "        self.invested = 0\n",
    "        self.market_price = np.nan\n",
    "        self.unrealized_gain = 0\n",
    "        self.realized_gain = 0\n",
    "        self.cash_on_hand = np.nan\n",
    "        self.purchase_history = pd.DataFrame(columns=[\"Date\",\"Shares\",\"Price\"])\n",
    "        self.ownership_history = pd.DataFrame(columns=[\"Date\",\"Ticker\",\"Market_Price\",\n",
    "                                                       \"Shares\",\"Equity\",\"Invested\",\n",
    "                                                       \"Unrealized_Gains\",\"Realized_Gains\",\n",
    "                                                       \"Gains\"])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Position for {}\".format(self.stock.ticker)\n",
    "        \n",
    "    def buy(self, quantity, date):\n",
    "        self.shares = self.shares + quantity\n",
    "        self.market_price = subset_by_dateindex(self.stock.historical_data, date, date).iloc[0][0]\n",
    "        self.invested = self.invested + (quantity*self.market_price)\n",
    "        self.equity = self.shares*self.market_price\n",
    "        self.unrealized_gain = self.equity - self.invested\n",
    "        self.purchase_history = self.purchase_history.append({\"Date\":date,\"Shares\":quantity,\"Price\":self.market_price}, ignore_index=True)\n",
    "        \n",
    "        #Realized gains including dividends\n",
    "        if date in self.stock.dividends.index:\n",
    "            self.realized_gain = self.realized_gain + (self.shares * subset_by_dateindex(self.stock.dividends, date, date).iloc[0][0])\n",
    "        \n",
    "        #Update ownership history - a dataframe with all relevant stats for every day\n",
    "        self.ownership_history = self.ownership_history.append({\"Date\":date,\"Ticker\":self.stock.ticker,\"Market_Price\":self.market_price,\n",
    "                                                               \"Shares\":self.shares,\"Equity\":self.equity,\"Invested\":self.invested,\n",
    "                                                               \"Unrealized_Gains\":self.unrealized_gain, \"Realized_Gains\":self.realized_gain,\n",
    "                                                               \"Gains\":(self.unrealized_gain + self.realized_gain)}, ignore_index=True)\n",
    "        \n",
    "    def sell(self, quantity, date):\n",
    "        self.shares = self.shares - quantity\n",
    "        self.market_price = subset_by_dateindex(self.stock.historical_data, date, date).iloc[0][0]\n",
    "        self.equity = self.shares*self.market_price    \n",
    "        self.purchase_history = sell_order(self.purchase_history, date, quantity)\n",
    "        invested_prior_to_sell = self.invested\n",
    "        self.invested = sum(self.purchase_history[['Shares','Price']].prod(axis=1))\n",
    "        self.unrealized_gain = self.equity - self.invested\n",
    "        self.realized_gain = self.realized_gain + ((quantity*self.market_price)-(invested_prior_to_sell-self.invested))\n",
    "\n",
    "        #Realized gains including dividends\n",
    "        if date in self.stock.dividends.index:\n",
    "            self.realized_gain = self.realized_gain + (self.shares * subset_by_dateindex(self.stock.dividends, date, date).iloc[0][0]) + ((quantity*self.market_price)-(invested_prior_to_sell-self.invested))\n",
    "        else:\n",
    "            self.realized_gain = self.realized_gain + ((quantity*self.market_price)-(invested_prior_to_sell-self.invested))\n",
    "        \n",
    "        #Update ownership history - a dataframe with all relevant stats for every day\n",
    "        self.ownership_history = self.ownership_history.append({\"Date\":date,\"Ticker\":self.stock.ticker,\"Market_Price\":self.market_price,\n",
    "                                                               \"Shares\":self.shares,\"Equity\":self.equity,\"Invested\":self.invested,\n",
    "                                                               \"Unrealized_Gains\":self.unrealized_gain, \"Realized_Gains\":self.realized_gain,\n",
    "                                                               \"Gains\":(self.unrealized_gain + self.realized_gain)}, ignore_index=True)\n",
    "        \n",
    "        \n",
    "    def update(self, date):\n",
    "        self.market_price = subset_by_dateindex(self.stock.historical_data, date, date).iloc[0][0]\n",
    "        self.equity = self.shares * self.market_price\n",
    "        self.unrealized_gain = self.equity - self.invested        \n",
    "\n",
    "        #Realized gains including dividends\n",
    "        if date in self.stock.dividends.index:\n",
    "            self.realized_gain = self.realized_gain + (self.shares * subset_by_dateindex(self.stock.dividends, date, date).iloc[0][0])\n",
    "        \n",
    "        #Update ownership history - a dataframe with all relevant stats for every day\n",
    "        self.ownership_history = self.ownership_history.append({\"Date\":date,\"Ticker\":self.stock.ticker,\"Market_Price\":self.market_price,\n",
    "                                                               \"Shares\":self.shares,\"Equity\":self.equity,\"Invested\":self.invested,\n",
    "                                                               \"Unrealized_Gains\":self.unrealized_gain, \"Realized_Gains\":self.realized_gain,\n",
    "                                                               \"Gains\":(self.unrealized_gain + self.realized_gain)}, ignore_index=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-l5K51mHu-C",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's continue with out AAPL example above. Say we bouth 10 stocks on 2017-3-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "riiLvPnBHs_J",
    "outputId": "612b6bc1-58d3-4ff4-f8fd-c1ea420f649a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aapl_pos = Position(aapl)\n",
    "aapl_pos.buy(10, \"2017-3-2\")\n",
    "print(f\"The number of shares is {aapl_pos.shares}\")\n",
    "print(f\"The market price at which the stocks were bought is ${aapl_pos.market_price}\")\n",
    "print(f\"Your equity of the stock is ${aapl_pos.equity}\")\n",
    "print(f\"Your unrealized gain/loss is ${aapl_pos.unrealized_gain}\")\n",
    "aapl_pos.ownership_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EdUojKOSIWNu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As you guessed, this is stating the information based on the day of purchase. What does that mean? There is no unrealized gain or loss, and all the information is static from the date you purchased said stocks. So, let's update our position for the next day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "MQLPwY0IIMOZ",
    "outputId": "0383a610-2d36-4722-a6a3-5580355fb34f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aapl_pos.update(\"2017-3-3\")\n",
    "print(f\"The number of shares is {aapl_pos.shares}\")\n",
    "print(f\"The market price the day after the stocks were bought is ${aapl_pos.market_price}\")\n",
    "print(f\"Your equity of the stock is ${aapl_pos.equity}\")\n",
    "print(f\"Your unrealized gain/loss is ${aapl_pos.unrealized_gain}\")\n",
    "aapl_pos.ownership_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5TJW2gTtJD0w",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In just one day, our position has increased by $7.8. What is we sold half of our equity the day afterwards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "IsN3uFhVJj8O",
    "outputId": "f761c850-e0e3-4dd9-b856-a462fd8cacb4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aapl_pos.sell(5,\"2017-3-6\")\n",
    "print(f\"The number of shares is {aapl_pos.shares}\")\n",
    "print(f\"The market price two days after the stocks were bought is ${aapl_pos.market_price}\")\n",
    "print(f\"Your equity of the stock is ${aapl_pos.equity}\")\n",
    "print(f\"Your unrealized gain/loss is ${aapl_pos.unrealized_gain}\")\n",
    "aapl_pos.ownership_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLr6CHTDJ3X6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Our equity has almost halved! This makes sense since we sold half of the shares. Our unrealized gains also dropped significantly. This is because half of the unrealized gains became realized gains, and the rest devalued due to the drop of the market price today.\n",
    "\n",
    "\n",
    "Alright alright... you get it! \n",
    "\n",
    "The next block defined functions to load the portfolio and get the portfolio data for a specified feature. What does this mean? \n",
    "\n",
    "Loading the portfolio is simply creating a Position object for every stock in our portfolio (defined by the csv imported above) and updating it every day from the first purchase until today. \n",
    "\n",
    "Note that the names of the columns of your personal csv file with your transactions must match the imported one above. That is, the ticker column's name is Symbol, the quantity is Qty, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ol5tjJ5vKRun",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_portfolio(transactions):\n",
    "    \"\"\"\n",
    "    Loads portfolio object from a dataframe of transactions.\n",
    "    Requires the Stock and Position objects.\n",
    "    Returns a dictionary with the position of every stock in the portfolio.\n",
    "    \"\"\"\n",
    "    stocks = transactions.Symbol.unique()\n",
    "    stock_dict = dict(zip(stocks, [None]*len(stocks)))\n",
    "    for stock_name in stocks:\n",
    "        stock_transactions = transactions[transactions['Symbol'] == stock_name]\n",
    "        earliest_date = min(stock_transactions['Open date'])\n",
    "        position = Position(Stock(stock_name))\n",
    "        stock_dates = position.stock.historical_data.index\n",
    "        for day_active_market in list(stock_dates[stock_dates >= earliest_date]):\n",
    "            day_transaction = stock_transactions[stock_transactions['Open date'] == str(day_active_market)]\n",
    "            if len(day_transaction) == 1:\n",
    "                purchase_type = day_transaction.Type.values\n",
    "                quantity = day_transaction.Qty.values[0]\n",
    "                if purchase_type == \"Buy\":\n",
    "                    position.buy(quantity, day_active_market)\n",
    "                    print(f\"You bought {quantity} shares of {stock_name} on {str(day_active_market)[:10]} for ${round(position.market_price,2)}\")\n",
    "                else:\n",
    "                    position.sell(quantity, day_active_market)\n",
    "                    print(f\"You sold {quantity} shares of {stock_name} on {str(day_active_market)[:10]} for ${round(position.market_price,2)}\")\n",
    "            else:\n",
    "                position.update(day_active_market)\n",
    "        stock_dict[stock_name] = position\n",
    "    return stock_dict\n",
    "\n",
    "def get_portfolio_feature_data(portfolio, feature, return_type = 'perStock'):\n",
    "    \"\"\"\n",
    "    Returns dataframe with the specified feature of each stock or a combination of all stocks\n",
    "    Input:\n",
    "    1. portfolio: a Portfolio object\n",
    "    2. feature: the feature in the ownership_history dataframe within a portfolio object to return\n",
    "    3. return_type: either 'perStock' or 'combined' - returns a dataframes with the features with a column for every stock or a summation of the values of all stocks\n",
    "    \"\"\"\n",
    "    stocks = list(portfolio.stock_positions.keys())\n",
    "    df_to_return = pd.DataFrame()\n",
    "    for s in stocks:\n",
    "        stock_column = portfolio.stock_positions[s].ownership_history.set_index('Date')[[feature]].rename(columns={feature:s})\n",
    "        stock_column.replace(0,np.nan,inplace=True)\n",
    "        df_to_return = pd.concat([df_to_return, stock_column], sort=False, axis=1)\n",
    "    if return_type == 'perStock':\n",
    "        return df_to_return\n",
    "    elif return_type == 'combined':\n",
    "        string = \"Total_\"+str(feature)\n",
    "        return pd.DataFrame(df_to_return.sum(axis=1), columns=[string])\n",
    "    return df_to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tfWsj3-2Llzu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that these functions have been defined, let's create our **Portfolio** object!\n",
    "\n",
    "All it will need for an input is the csv imported above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f00rKt4aLbtQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Portfolio:\n",
    "    def __init__(self, transactions):\n",
    "        self.stock_positions = load_portfolio(transactions)\n",
    "        \n",
    "    def plot_portfolio_feature(self, feature):\n",
    "        return get_portfolio_feature_data(self, feature, return_type='combined').plot(figsize=(15,8))\n",
    "    \n",
    "    def plot_feature_perStock(self, feature):\n",
    "        return get_portfolio_feature_data(self, feature, return_type='perStock').plot(figsize=(15,8))\n",
    "    \n",
    "    def plot_portfolio(self):\n",
    "        invested = get_portfolio_feature_data(self, 'Invested', 'combined')\n",
    "        maxinvested = max(invested['Total_Invested'])\n",
    "        combined_return = get_portfolio_feature_data(self, 'Gains', 'combined')/maxinvested\n",
    "        return combined_return.plot(figsize=(15,8))\n",
    "        \n",
    "    def portfolio_from_to(self, start_date=None, end_date=None, market_ticker = \"^GSPC\"):\n",
    "        invested = get_portfolio_feature_data(self, 'Invested', 'combined')\n",
    "        invested = subset_by_dateindex(invested, start_date, end_date)\n",
    "        maxinvested = max(invested['Total_Invested'])\n",
    "        unr_gain_at_dates = subset_by_dateindex(get_portfolio_feature_data(self, 'Gains', 'combined'), start_date, end_date)\n",
    "        print(unr_gain_at_dates)\n",
    "        adj_gains = unr_gain_at_dates-unr_gain_at_dates.iloc[0]\n",
    "        combined_return = adj_gains/maxinvested\n",
    "        \n",
    "        if start_date == None:\n",
    "            start_date = min(unr_gain_at_dates.index)\n",
    "        market = import_stock_data(market_ticker, start_date, end_date)\n",
    "        adj_market = market-market.iloc[0]\n",
    "        \n",
    "        with_market = combined_return\n",
    "        with_market[market_ticker] = adj_market/market.iloc[0]\n",
    "        \n",
    "        ret_dataframe = pd.DataFrame({\"Portfolio\":[f\"${round(adj_gains.iloc[-1][0],2)}\",\n",
    "                                                   f\"{round(combined_return.iloc[-1][0]*100,2)}%\"],\n",
    "                                     \"Market\":[' ',\n",
    "                                               f\"{round((100*adj_market/market.iloc[0]).iloc[-1][0],2)}%\"]}, \n",
    "                                     index=['Gains','Return'])\n",
    "        \n",
    "        #Show Plot\n",
    "        with_market.plot(figsize=(15,8))\n",
    "        plt.show()\n",
    "        \n",
    "        return ret_dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ge42Ajfg8gOv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "facebook_transactions = pd.DataFrame({\"Symbol\":[\"FB\",\"FB\",\"FB\"],\n",
    "                        \"Qty\":[100,100,50],\n",
    "                        \"Type\":[\"Buy\",\"Buy\",\"Sell\"],\n",
    "                        \"Open date\":[datetime(2020, 1,2),datetime(2020,2,3),datetime(2020,2,18)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "tB3-Ro4F8gV3",
    "outputId": "8baf3a0e-1a06-4b75-b4ed-528e66a8ba10",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "facebook_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "d_6NnSde8ga9",
    "outputId": "931657de-acb2-47cb-fcee-95bd598a4fd0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "myP_FB = Portfolio(facebook_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tqPztUEC8gds",
    "outputId": "08bd70de-d8f8-44a6-a8e4-f2f66975e616",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "myP_FB.portfolio_from_to(end_date = \"2020-02-19\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "YT5izRELLsap",
    "outputId": "119c396a-0f8d-4b1d-f8e9-738504285806",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_portfolio = Portfolio(investment_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "id": "2l9JoOBGL0oR",
    "outputId": "c92518f9-eb49-4229-8565-3b6f6d13a01c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_portfolio.portfolio_from_to()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "id": "0H3gYVEcQdJU",
    "outputId": "295f335b-86dc-45fb-8fd4-c4b5fc575a8e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_portfolio.plot_portfolio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "lJnWJlWcRmpq",
    "outputId": "bf275440-13e7-45e4-dda4-27c4cdccc904",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_portfolio.plot_feature_perStock('Gains')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVvkkDgMvoUV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's check whether the integration of dividends worked.\n",
    "\n",
    "Let's take into consideration AAPL. AAPL has given dividends since 2015. We can see that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "colab_type": "code",
    "id": "VnByubkQu_-m",
    "outputId": "512fae43-2a74-4f99-c29b-8d9eea1cd90f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import_stock_dividends('AAPL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QuJukh6HwA-k",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In our current portfolio, we have bought AAPL twice. Once in 2015 for \\$102 per share (30 shares total) and the second time in 2017 for \\$148 per share (22 shares: 52 shares total). We have **not** sold AAPL once. \n",
    "\n",
    "What does this entail? Well, if we have not sold AAPL at any point, we should not have any unrealized gains, except those that are generated through dividends!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "1jDSmAaOWyvf",
    "outputId": "a3441489-d7e5-447d-a45c-47c5385f156f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_portfolio.stock_positions['AAPL'].purchase_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "BRa3AA5cu5Zz",
    "outputId": "90b2a7d5-26ee-44d0-8239-ee02224c9872",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_portfolio.stock_positions['AAPL'].ownership_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZTbYsetwq7j",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we can see from the ownership history of AAPL in our portfolio, we have realized gains! This means that dividends are being computed, and that we have generated \\$560 from dividends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Hy87eYEvzil",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Portfolio_Backend.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}